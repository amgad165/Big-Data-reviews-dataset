{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21abb367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.2.1-bin-hadoop3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc91b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e329b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df94bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"multiLine\", \"true\").load(\"reviews.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e6d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.select('paper.review').collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc035fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 405 405 405\n"
     ]
    }
   ],
   "source": [
    "confidence_col = []\n",
    "evaluation_col = []\n",
    "orientation_col = []\n",
    "timespan_col= []\n",
    "for i in review:\n",
    "    for j in i:\n",
    "        confidence_col.append(j[0])\n",
    "        evaluation_col.append(j[1])\n",
    "        orientation_col.append(j[4])\n",
    "        timespan_col.append(j[7])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6416564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+----------+\n",
      "|confidence|evaluation|orientation|  timespan|\n",
      "+----------+----------+-----------+----------+\n",
      "|         4|         1|          0|2010-07-05|\n",
      "|         4|         1|          1|2010-07-05|\n",
      "|         5|         1|          1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         3|         2|          1|2010-07-05|\n",
      "|         3|         0|         -1|2010-07-05|\n",
      "|         4|         2|          2|2010-07-05|\n",
      "|         2|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         5|         2|          1|2010-07-05|\n",
      "|         4|        -1|          0|2010-07-05|\n",
      "|         4|        -2|         -1|2010-07-05|\n",
      "|         4|         1|         -1|2010-07-05|\n",
      "|         5|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         1|          0|2010-07-05|\n",
      "+----------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# intialise data of lists.\n",
    "data = {'confidence':confidence_col,\n",
    "       'evaluation':evaluation_col,'orientation':orientation_col,'timespan':timespan_col}\n",
    "  \n",
    "# Create DataFrame\n",
    "review_data = pd.DataFrame(data)\n",
    "review_data = review_data.dropna()\n",
    "review_data ['confidence']= review_data[['confidence']].astype(int)\n",
    "review_data ['orientation']= review_data[['orientation']].astype(int)\n",
    "review_data ['evaluation']= review_data[['evaluation']].astype(int)\n",
    "\n",
    "review_data = spark.createDataFrame(data=review_data)\n",
    "review_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841262b",
   "metadata": {},
   "source": [
    "# Sampling/filtering RDDs to pick out relevant data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933ee964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39d56b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9679691791534424"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = review_data.sample(False, 0.1, 42)\n",
    "\n",
    "contains_date_sample = sampled.filter(sampled.timespan =='2010')\n",
    "t0 = time()\n",
    "num_sampled = contains_date_sample.count()\n",
    "duration = time() - t0\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7493386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1085140705108643"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "contains_date_all = review_data.filter(review_data.timespan =='2010')\n",
    "t0 = time()\n",
    "num_sampled = contains_date_sample.count()\n",
    "duration = time() - t0\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b103bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sample = sampled.filter(sampled.timespan =='2010')\n",
    "non_date_sample = sampled.subtract(date_sample)\n",
    "\n",
    "sampled.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52292025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sample.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fb8f8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_date_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78152cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = sampled.rdd.map(lambda features: features[1]).distinct()\n",
    "feature_2 = sampled.rdd.map(lambda features: features[3]).distinct()\n",
    "f1 = feature_1.collect()\n",
    "f2 = feature_2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d727032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, -2, -1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1cb92b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010-07-05', '2015-07-05', '2014-07-05', '2013-07-05']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cedf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
