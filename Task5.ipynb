{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21abb367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.2.1-bin-hadoop3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc91b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e329b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df94bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"multiLine\", \"true\").load(\"reviews.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238777cc",
   "metadata": {},
   "source": [
    "# Putting structure on your Big Data with SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299f689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.select('paper.review').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38e1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_col = []\n",
    "evaluation_col = []\n",
    "orientation_col = []\n",
    "timespan_col= []\n",
    "for i in review:\n",
    "    for j in i:\n",
    "        confidence_col.append(j[0])\n",
    "        evaluation_col.append(j[1])\n",
    "        orientation_col.append(j[4])\n",
    "        timespan_col.append(j[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d9a7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+----------+\n",
      "|confidence|evaluation|orientation|  timespan|\n",
      "+----------+----------+-----------+----------+\n",
      "|         4|         1|          0|2010-07-05|\n",
      "|         4|         1|          1|2010-07-05|\n",
      "|         5|         1|          1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         3|         2|          1|2010-07-05|\n",
      "|         3|         0|         -1|2010-07-05|\n",
      "|         4|         2|          2|2010-07-05|\n",
      "|         2|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         5|         2|          1|2010-07-05|\n",
      "|         4|        -1|          0|2010-07-05|\n",
      "|         4|        -2|         -1|2010-07-05|\n",
      "|         4|         1|         -1|2010-07-05|\n",
      "|         5|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         1|          0|2010-07-05|\n",
      "+----------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# intialise data of lists.\n",
    "data = {'confidence':confidence_col,\n",
    "       'evaluation':evaluation_col,'orientation':orientation_col,'timespan':timespan_col}\n",
    "  \n",
    "# Create DataFrame\n",
    "review_data = pd.DataFrame(data)\n",
    "review_data = review_data.dropna()\n",
    "review_data ['confidence']= review_data[['confidence']].astype(int)\n",
    "review_data ['orientation']= review_data[['orientation']].astype(int)\n",
    "review_data ['evaluation']= review_data[['evaluation']].astype(int)\n",
    "\n",
    "review_data = spark.createDataFrame(data=review_data)\n",
    "review_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec35978",
   "metadata": {},
   "source": [
    "# Putting structure on your Big Data with SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00df568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark-3.2.1-bin-hadoop3.2\\python\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "review_data.registerTempTable(\"rdd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f391c2c",
   "metadata": {},
   "source": [
    "## Manipulating DataFrames with SparkSQL schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16cfae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|confidence|\n",
      "+----------+\n",
      "|         2|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT confidence FROM rdd WHERE evaluation < 2 AND orientation > 1\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd842f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|confidence|\n",
      "+----------+\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         5|\n",
      "|         4|\n",
      "|         4|\n",
      "|         3|\n",
      "|         3|\n",
      "|         3|\n",
      "|         4|\n",
      "|         3|\n",
      "|         5|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         3|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT confidence FROM rdd WHERE evaluation > 0 AND orientation < 1\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35812232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|confidence|  timespan|\n",
      "+----------+----------+\n",
      "|         4|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         5|2010-07-05|\n",
      "|         3|2010-07-05|\n",
      "|         2|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         5|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         5|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         5|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         3|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "|         3|2010-07-05|\n",
      "|         4|2010-07-05|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT confidence,timespan FROM rdd WHERE evaluation < 2 AND timespan = '2010-07-05'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935d29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
