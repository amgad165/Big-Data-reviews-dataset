{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dce756",
   "metadata": {},
   "source": [
    "# Powerful Exploratory Data Analysis with Machine Learning\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21abb367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.2.1-bin-hadoop3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc91b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e329b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df94bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"multiLine\", \"true\").load(\"reviews.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7511387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.select('paper.review').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38e1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_col = []\n",
    "evaluation_col = []\n",
    "orientation_col = []\n",
    "timespan_col= []\n",
    "for i in review:\n",
    "    for j in i:\n",
    "        confidence_col.append(j[0])\n",
    "        evaluation_col.append(j[1])\n",
    "        orientation_col.append(j[4])\n",
    "        timespan_col.append(j[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d9a7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+----------+\n",
      "|confidence|evaluation|orientation|  timespan|\n",
      "+----------+----------+-----------+----------+\n",
      "|         4|         1|          0|2010-07-05|\n",
      "|         4|         1|          1|2010-07-05|\n",
      "|         5|         1|          1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         3|         2|          1|2010-07-05|\n",
      "|         3|         0|         -1|2010-07-05|\n",
      "|         4|         2|          2|2010-07-05|\n",
      "|         2|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         5|         2|          1|2010-07-05|\n",
      "|         4|        -1|          0|2010-07-05|\n",
      "|         4|        -2|         -1|2010-07-05|\n",
      "|         4|         1|         -1|2010-07-05|\n",
      "|         5|        -2|         -1|2010-07-05|\n",
      "|         4|         2|          0|2010-07-05|\n",
      "|         4|         1|          0|2010-07-05|\n",
      "+----------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# intialise data of lists.\n",
    "data = {'confidence':confidence_col,\n",
    "       'evaluation':evaluation_col,'orientation':orientation_col,'timespan':timespan_col}\n",
    "  \n",
    "# Create DataFrame\n",
    "review_data = pd.DataFrame(data)\n",
    "review_data = review_data.dropna()\n",
    "review_data ['confidence']= review_data[['confidence']].astype(int)\n",
    "review_data ['orientation']= review_data[['orientation']].astype(int)\n",
    "review_data ['evaluation']= review_data[['evaluation']].astype(int)\n",
    "\n",
    "review_data = spark.createDataFrame(data=review_data)\n",
    "review_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff7db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.573200992555831"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "confidencerd = review_data.rdd.map(lambda x: [int(x[0])])\n",
    "\n",
    "summary = Statistics.colStats(confidencerd)\n",
    "summary.mean()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e498a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443410847884276"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt \n",
    "sqrt(summary.variance()[0])  # std. dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210a91a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722135f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a606f02",
   "metadata": {},
   "source": [
    "### Using pearson and spearman to discover correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d48ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.04019695, -0.08341732],\n",
       "       [-0.04019695,  1.        ,  0.78031129],\n",
       "       [-0.08341732,  0.78031129,  1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = review_data.rdd.map(lambda x: [x[0], x[1], x[2]])\n",
    "Statistics.corr(metrics, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b925f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.03831504, -0.06309566],\n",
       "       [-0.03831504,  1.        ,  0.76959781],\n",
       "       [-0.06309566,  0.76959781,  1.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(metrics, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd3057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 4 \n",
      "statistic = 0.5852136752136753 \n",
      "pValue = 0.9646925263439344 \n",
      "No presumption against null hypothesis: observed follows the same distribution as expected..\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "visitors_freq = Vectors.dense(0.13, 0.61, 0.8, 0.5, 0.3)\n",
    "print(Statistics.chiSqTest(visitors_freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
